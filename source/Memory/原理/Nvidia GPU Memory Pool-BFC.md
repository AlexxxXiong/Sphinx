# Nvidia GPU Memory Pool-BFC

----

内存池是linux系统中一种高效的内存管理机制。它预先分配一定数量的内存块并形成一个池，以便在需要内存时可以快速分配内存。与传统的内存分配方式相比，内存池管理可以大大提高内存分配和释放的效率，减少内存碎片的产生。

https://bruce-lee-ly.medium.com/nvidia-gpu-memory-pool-bfc-d3502b355a82



在计算机内存管理中，伙伴系统和页表有不同的角色，但它们之间仍然存在联系。让我们分别定义这两个概念，并了解它们之间的联系。

### 1. 页表（Page Table）
- **功能：** 将虚拟地址映射到物理地址，实现虚拟内存管理。
- **结构：**
  - 由页目录（Page Directory）和页表（Page Table）构成。
  - 虚拟地址通过多级页表转换成物理地址。
  - 虚拟地址通常分成页目录、页表和页偏移三个部分。
  
### 2. 伙伴系统（Buddy System）
- **功能：** 管理物理内存的分配与释放。
- **结构：**
  - 将物理内存按2的幂次划分成多个块（block），每个大小称为一个order。
  - 每个order的块按大小分类成不同的`bin`，在每个`bin`中包含多个块，称为`chunk`或`block`。

### 页表和伙伴系统之间的联系
1. **物理内存的管理：**
   - 页表管理虚拟地址空间的映射。
   - 页表中的物理页框号指向实际的物理内存地址。
   - 伙伴系统在物理内存中维护这些物理页框。
   - 因此，伙伴系统通过页表提供的虚拟地址映射，管理实际的物理内存。

2. **物理页框的分配：**
   - 页表中的每个页框指向一个实际的物理页。
   - 当需要分配新的页框时，伙伴系统负责分配实际的物理内存。
   - 伙伴系统根据页表的映射关系，将物理内存分配给特定的虚拟地址空间。

3. **内存回收：**
   - 当释放内存时，页表会更新映射关系，标记相应的页框为可用状态。
   - 伙伴系统接管已释放的物理页框，并将其重新加入适当的`bin`。

### 简化的关系示意图
```
虚拟内存 -> 页表 -> 物理页框号 -> 伙伴系统的`bin`（物理内存块）
```

### 流程举例
1. **分配内存：**
   1. 请求从虚拟内存分配一个页面。
   2. 查找页表，将虚拟页映射到一个空闲的物理页框。
   3. 伙伴系统为物理页框分配实际的内存块。

2. **释放内存：**
   1. 请求释放某个虚拟内存页面。
   2. 更新页表映射，标记对应的物理页框为可用。
   3. 伙伴系统将该物理内存块返回到合适的`bin`中。

### 结论
- 页表和伙伴系统通过虚拟地址到物理地址的映射关系建立联系。
- 页表负责管理虚拟地址空间，伙伴系统负责实际的物理内存管理。
- 伙伴系统与页表的结合提供了高效的虚拟内存管理与物理内存分配。







## 1.1 Linux内核内存池

- **Buddy 系统**：操作系统通常使用 `Buddy` 系统来分配和管理内存块。然而，`Buddy` 系统更适合管理大块内存，对于小对象的频繁分配与释放效率较低。
- **内存碎片**：频繁的小对象分配和释放容易导致大量内存碎片，降低内存利用效率。

在linux内核中，内存池管理主要采用以下两种方法：

### (1) Buddy System

伙伴系统以页为单位管理和分配内存。内存池中所有内存块的大小为2^n。

它将所有空闲页框分组到11个块链表中。

每个块链表包含大小为1、2、4、8、16、32、64、128、256、512和1024个连续页框的页框块。

当需要分配一块内存时，分配器会在内存池中找到最小的可用块，并将其分配给用户。

当不再使用某个内存块时，分配器将释放它并检查其“兄弟块”。

如果兄弟块也空闲，则将它们合并成一个大块，并继续向上检查，直到无法再合并为止。 



buddy系统的优点是可以减少内存碎片的产生，同时也提高了内存分配的效率。

然而，这种方法也有一些缺点。例如，大小不规则的内存块的分配和释放不方便，还可能存在内存的浪费。





### (2) Slab Allocator

slab分配器是在buddy系统分配的大内存的基础上进一步细化的小内存分配方法。

主要针对一些经常分配和释放的小对象，通常是内核数据结构。

**每当申请这样的对象时，slab分配器就会从slab列表中分配一个这个大小的单元，**

**当它被释放时，再次将其保存在列表中，而不是直接返回给伙伴系统，从而避免内部碎片。**



lab分配器可以高效地处理频繁申请和释放小对象（例如内核数据结构）的内存事务。

同时，可以显着节省内存空间，避免过多的内存碎片。



#### Slab 分配器的结构与工作机制

1. **Slab、Cache 和 Object**
   - **Slab**：由一块连续的物理内存区域组成，包含若干固定大小的对象。
   - **Cache**：由多个 Slab 组成，针对特定类型的小对象（如内核数据结构）进行优化管理。
   - **Object**：实际的小对象，保存在 Slab 内。
2. **分配与释放流程**
   - **分配对象**：
     - 当请求一个小对象时，Slab 分配器会从目标 Cache 中的 Slab 列表中分配一个空闲对象。
     - 如果当前 Cache 中没有空闲的 Slab，可以从 `Buddy` 系统申请一个新的 Slab，并将其添加到 Cache 中。
     - 分配成功的对象会标记为已使用状态。
   - **释放对象**：
     - 当对象被释放时，Slab 分配器将其标记为可用，并返回到相应的 Slab。
     - **该对象不会立即归还给 `Buddy` 系统，而是保持在 Cache 中以供后续分配使用。**
     - **如果一个 Slab 中的所有对象都空闲，则该 Slab 可以被归还给 `Buddy` 系统。**
3. **避免内部碎片**
   - **保持对象池**：对象释放后保持在 Cache 中而不是直接归还给 `Buddy` 系统，从而避免内部碎片。
   - **预分配对象池**：每个 Cache 都有一个预分配对象池（即空闲对象列表），减少频繁的分配与释放操作。

```c
struct kmem_cache {
    ...
    struct list_head slabs_full;    // 满载的 Slab 链表
    struct list_head slabs_partial; // 部分使用的 Slab 链表
    struct list_head slabs_free;    // 空闲的 Slab 链表
    ...
};

void *kmem_cache_alloc(struct kmem_cache *cache, gfp_t flags) {
    struct slab *slab;
    void *obj;

    // 从部分使用的 Slab 链表中分配对象
    slab = list_first_entry_or_null(&cache->slabs_partial, struct slab, list);
    if (slab) {
        obj = slab_alloc(slab, cache, flags);
        if (obj) {
            return obj;
        }
    }

    // 如果没有可用的对象，分配新的 Slab
    slab = kmem_cache_grow(cache, flags);
    if (!slab) {
        return NULL;
    }

    // 从新分配的 Slab 中分配对象
    return slab_alloc(slab, cache, flags);
}

```



### 主要优点

1. **效率高**：
   - **频繁分配和释放**：针对内核数据结构等频繁分配和释放的小对象操作提供优化。
   - **预分配对象池**：对象池中的对象可以快速重复使用。
2. **内存节省**：
   - **减少内存碎片**：通过保持对象池避免了直接归还给 `Buddy` 系统而产生的内部碎片。
   - **对象重用**：保持对象池中的对象以供快速分配和重用。

### 总结

这段话主要强调了以下内容：

1. **Slab 分配器的作用**：针对频繁分配和释放的小对象提供更高效的内存管理。

2. **工作机制**：保持对象池避免内部碎片，快速分配与释放对象。

3. 优势

   ：

   - 避免直接归还给 `Buddy` 系统导致的内部碎片。
   - 高效处理频繁的小对象内存事务。













对于TensorFlow和PyTorch的内存分配机制及其初始分配规则，可以通过查看它们的源代码来获取更详细的信息。下面是一些指导，帮助你了解这些规则在源代码中是如何实现的：

### TensorFlow

在TensorFlow中，内存管理主要由BFC（Best-Fit with Coalescing）分配器处理，它负责GPU内存的分配。要找到与内存分配相关的代码和初始分配规则：

- **源码位置**：TensorFlow的内存分配器实现位于`tensorflow/core/common_runtime/bfc_allocator.cc`。这里包含了BFC分配器的逻辑，包括它是如何初始化内存池的。
- **初始化规则**：在BFC分配器的初始化过程中，会基于用户的配置或默认设置来决定初始的内存大小。如果启用了内存增长，初始分配通常较小，并根据需要进行调整。

### PyTorch

PyTorch使用缓存分配器来管理CUDA内存，这种策略的实现有助于动态地回收和重新分配内存，从而优化内存使用：

- **源码位置**：PyTorch的CUDA内存分配器代码主要在`c10/cuda/CUDACachingAllocator.cpp`中。这个文件包含了缓存分配器的核心实现。
- **初始化规则**：PyTorch的内存分配器在模型开始运行时不会立即申请大量内存。它根据模型运行时的需求动态地分配和释放内存，初始分配通常是按需进行的。

这些文件包含了内存分配的具体实现逻辑，你可以通过查看这些源文件来获取关于内存分配策略和初始化规则的详细信息。如果你对源代码有进一步的问题或需要帮助理解特定部分，随时可以询问！





## 1.2 其他内存池

(1) tcmalloc

Tcmalloc是Google开发的高效稳定的内存分配器。它采用slab技术，可以有效避免内存碎片。在多线程环境下的性能非常好，速度也比较快，适合在大规模、高并发的分布式集群系统中使用。同时支持调整参数，可以根据不同的应用场景和硬件配置进行适当调整，使内存分配更加高效。

tcmalloc不支持动态内存分配，因此不能与系统内置的内存分配器交互使用。并且由于tcmalloc需要优化，需要增大二进制文件的大小，影响加载速度。

(2) jemalloc

Jemalloc 是 FreeBSD 开发的通用内存分配器。它主要使用分层分配来管理内存。在多线程环境下，尤其是在虚拟机中，具有出色的分配和释放性能。并取得了良好的业绩。

Jemalloc采用固定大小的多级内存分配算法，很容易导致内存浪费，并且在内存分配速度上比tcmalloc稍慢。

> 这些都是知名的内存分配器。以下是它们的全称及简要介绍：
>
> 1. **jemalloc (Jason Evans malloc)**
>    - **全称**：Jason Evans Memory Allocator
>    - **管理内存方式**：使用分层结构和多级内存池来管理内存。通过合并空闲块来减少内存碎片。
>    - **针对问题**：优化内存分配性能和减少内存碎片。
>    - **考虑点**：平衡内存使用效率和分配速度。
>
> 2. **llalloc (Low Latency Alloc)**
>    - **全称**：Low Latency Allocator
>
>    - **管理内存方式**：旨在提供低延迟内存分配，特别适用于实时系统。
>
>    - **针对问题**：降低内存分配和释放的延迟。
>
>    - **考虑点**：极低的分配延迟。
>
>      > 下面我将具体描述LLAlloc的那些专门为实时性设计的特性，这些特性在其他分配器中可能没有或者没有经过专门优化：
>      >
>      > ### 1. **确定性分配时间**
>      >
>      > LLAlloc通过设计确定性的数据结构和算法，保证内存分配和释放的时间是可预测和恒定的。传统分配器可能在不同情况下花费不同的时间，而LLAlloc的设计确保在最坏情况下也能保证分配时间不会超出预期。
>      >
>      > ### 2. **无锁数据结构**
>      >
>      > 与其他分配器不同，LLAlloc在尽可能多的地方采用了无锁（Lock-Free）或无等待（Wait-Free）数据结构。这些数据结构允许多个线程同时操作而不会产生锁争用，确保了分配和释放操作的低延迟和高并发性能。
>      >
>      > ### 3. **批处理操作**
>      >
>      > LLAlloc在内存分配和释放操作中使用了批处理技术。这意味着它可以一次性分配或释放多个内存块，减少频繁调用系统API带来的开销和延迟。批处理操作特别适用于实时系统，可以显著降低内存操作的总时间。
>      >
>      > ### 4. **固定大小内存池**
>      >
>      > LLAlloc使用多个固定大小的内存池，每个内存池管理特定大小范围的内存块。通过这种方式，分配和释放操作可以在常数时间内完成，因为内存块的大小是预先确定的，不需要复杂的计算和查找。
>      >
>      > ### 5. **缓存局部性优化**
>      >
>      > LLAlloc对缓存局部性进行了专门优化，确保分配的内存块尽可能使用当前线程的本地缓存，减少跨核访问带来的延迟。这对于多核系统中的实时应用尤其重要。
>      >
>      > ### 6. **预分配策略**
>      >
>      > LLAlloc在系统启动时会预先分配一部分内存块，并将其保存在快速访问的数据结构中。这样，当需要内存时，可以直接从预先分配的内存块中获取，避免了动态分配内存带来的延迟。
>      >
>      > ### 7. **实时垃圾回收**
>      >
>      > LLAlloc包含一个实时垃圾回收机制，能够在后台自动回收不再使用的内存块。这个垃圾回收过程是非阻塞的，不会影响实时任务的执行，从而保证系统的实时性能。
>      >
>      > ### 8. **优先级处理**
>      >
>      > LLAlloc支持优先级内存分配，可以根据任务的优先级来决定内存分配的顺序和策略。高优先级任务可以优先获得内存资源，确保关键任务的实时性要求。
>      >
>      > ### 9. **专用内存区域**
>      >
>      > LLAlloc可以为不同类型的任务预先划分专用内存区域，避免不同任务之间的内存争用。这种策略确保关键任务的内存操作不受其他任务的影响，从而保证其实时性能。
>      >
>      > ### 10. **内存分配策略优化**
>      >
>      > LLAlloc允许用户根据具体应用需求定制内存分配策略。通过优化内存分配算法和数据结构，确保分配操作在最坏情况下也能提供可预测的性能。
>      >
>      > 
>      >
>      > 任何优化都会有权衡，LLAlloc (Low Latency Allocator) 也不例外。尽管它在实时性方面有许多优点，但也存在一些缺点和权衡：
>      >
>      > ### 1. **内存使用效率**
>      > - **预分配和缓存**：为了保证低延迟，LLAlloc会预先分配大量内存块并保存在缓存中。这可能导致内存使用效率较低，未使用的内存块在缓存中闲置，增加了内存浪费。
>      > - **固定大小内存池**：使用固定大小的内存池虽然能提高分配速度，但也会造成内存碎片，尤其是当分配的内存块大小与实际需求不完全匹配时。
>      >
>      > ### 2. **复杂性和维护成本**
>      > - **无锁数据结构**：无锁数据结构和算法的实现较为复杂，容易出错且难以调试。这增加了分配器的复杂性和维护成本。
>      > - **专用内存区域和定制策略**：为不同类型的任务预先划分内存区域以及定制内存分配策略会增加系统设计和配置的复杂性。
>      >
>      > ### 3. **适用性限制**
>      > - **专为实时系统设计**：LLAlloc的设计目标是实时性，这使得它在其他类型的应用中（如普通的桌面应用或批处理系统）可能无法发挥其全部优势，甚至可能不如一些通用分配器高效。
>      > - **定制化需求**：虽然LLAlloc允许用户定制内存分配策略，但这也意味着需要对具体应用需求有深入了解，增加了使用门槛。
>      >
>      > ### 4. **内存碎片**
>      > - **分级内存池和批处理操作**：虽然分级内存池和批处理操作能提高分配速度，但可能会导致内存碎片，特别是在频繁分配和释放大小不一的内存块时，碎片问题可能更加突出。
>      >
>      > ### 5. **实时垃圾回收**
>      > - **实时垃圾回收**：虽然LLAlloc的实时垃圾回收机制能在后台自动回收内存，但这也引入了一定的开销。如果垃圾回收过程未能及时回收足够的内存，可能会影响实时性。
>      >
>      > ### 6. **资源占用**
>      > - **线程局部存储**：LLAlloc利用线程局部存储管理内存缓存，这可能会增加每个线程的内存占用量，特别是在高并发环境下，每个线程都有自己的缓存，会增加整体内存消耗。
>      >
>      > ### 总结
>      > LLAlloc在实时性方面的优化使其在实时系统中表现出色，但这些优化也带来了一些缺点和权衡，包括内存使用效率、系统复杂性、内存碎片问题以及适用性限制。使用LLAlloc时，需要根据具体应用场景权衡这些优缺点，以选择最合适的内存分配器。
>
> 3. **ptmalloc2 (Pthreads malloc 2)**
>    - **全称**：Pthreads Memory Allocator 2
>    - **管理内存方式**：基于Doug Lea的dlmalloc改进，支持多线程环境。
>    - **针对问题**：多线程环境中的内存分配。
>    - **考虑点**：线程安全和性能。
>
> 4. **TCMalloc (Thread-Caching Malloc)**
>    - **全称**：Thread-Caching Malloc
>    - **管理内存方式**：使用线程局部缓存减少锁争用，提高多线程环境中的分配速度。
>    - **针对问题**：高并发环境下的内存分配效率。
>    - **考虑点**：减少锁争用，提高分配速度。
>
> 5. **Hoard**
>    - **全称**：Hoard Memory Allocator
>    - **管理内存方式**：使用分级分配器和局部缓存来减少内存碎片和提高多线程性能。
>    - **针对问题**：减少内存碎片和提高多线程环境的性能。
>    - **考虑点**：线程局部缓存和全局缓存的平衡。
>
> 6. **scalloc (Scalable Malloc)**
>    - **全称**：Scalable Malloc
>    - **管理内存方式**：设计用于多核处理器的分配器，减少同步开销。
>    - **针对问题**：多核处理器环境下的内存分配效率。
>    - **考虑点**：减少同步开销，提高并发性。
>
> 7. **Streamflow**
>    - **全称**：Streamflow Memory Allocator
>    - **管理内存方式**：通过分配器池和流式分配策略来减少内存碎片。
>    - **针对问题**：减少内存碎片和提高分配性能。
>    - **考虑点**：流式分配策略。
>
>    > Streamflow Memory Allocator结合多种内存分配策略，以适应不同大小和类型的内存请求，从而优化内存分配效率。具体来说，它采用了以下几种策略：
>    >
>    > ### 1. 小块内存分配策略
>    >
>    > #### 快速分配算法（Fast Path Allocation）
>    > 对于小块内存，Streamflow使用快速分配算法，以确保内存分配操作的低延迟和高效率。这通常包括以下几种技术：
>    >
>    > - **线程局部缓存（Thread Local Cache）**：每个线程都有一个本地缓存，用于存储最近分配和释放的小块内存。分配和释放操作首先在本地缓存中进行，避免了全局锁争用，从而提高并发性能。
>    > - **固定大小分配（Fixed-Size Allocation）**：小块内存的分配和释放使用固定大小的内存池，这样可以在常数时间内完成分配和释放操作。固定大小的内存块减少了内存碎片，并且操作简单高效。
>    > - **快速路径（Fast Path）**：对于常见的小块内存分配请求，Streamflow实现了快速路径优化，使这些操作能够在最少的指令数内完成。
>    >
>    > #### 示例
>    > ```c
>    > void* allocate_small_block(size_t size) {
>    >     // 从线程局部缓存中分配内存块
>    >     void* block = thread_local_cache.allocate(size);
>    >     if (block == NULL) {
>    >         // 如果本地缓存为空，从全局池中分配
>    >         block = global_pool.allocate(size);
>    >     }
>    >     return block;
>    > }
>    > 
>    > void free_small_block(void* block) {
>    >     // 将内存块放回线程局部缓存
>    >     if (!thread_local_cache.free(block)) {
>    >         // 如果本地缓存已满，将内存块放回全局池
>    >         global_pool.free(block);
>    >     }
>    > }
>    > ```
>    >
>    > ### 2. 大块内存分配策略
>    >
>    > #### 分区分配（Partitioned Allocation）
>    > 对于大块内存，Streamflow使用分区分配策略。这种策略将内存池划分为多个分区，每个分区负责管理特定大小范围的内存块。分区分配策略减少了内存碎片，并且能够高效管理大块内存请求。
>    >
>    > - **分级自由列表（Segregated Free Lists）**：大块内存块按照大小分级存储在不同的自由列表中。当需要分配大块内存时，系统会在相应的自由列表中查找合适的内存块，从而提高分配效率。
>    > - **延迟合并（Deferred Coalescing）**：为了减少内存碎片，Streamflow采用延迟合并策略，在释放大块内存时不立即合并相邻的空闲块，而是将其放入延迟合并队列中。当内存碎片影响性能时，系统再进行合并操作。
>    > - **分区内存池（Partitioned Memory Pools）**：大块内存分配和释放操作在各自的分区内存池中进行，减少了全局锁的使用，提高了并发性能。
>    >
>    > #### 示例
>    > ```c
>    > void* allocate_large_block(size_t size) {
>    >     // 查找合适的分区
>    >     MemoryPool* pool = find_partition_pool(size);
>    >     // 从分区内存池中分配内存块
>    >     void* block = pool->allocate(size);
>    >     if (block == NULL) {
>    >         // 如果分区内存池没有可用块，尝试从系统分配
>    >         block = system_allocate(size);
>    >     }
>    >     return block;
>    > }
>    > 
>    > void free_large_block(void* block) {
>    >     // 查找内存块所属的分区
>    >     MemoryPool* pool = find_partition_pool_by_block(block);
>    >     // 将内存块放回分区内存池
>    >     pool->free(block);
>    >     // 触发延迟合并
>    >     if (should_coalesce(pool)) {
>    >         pool->coalesce();
>    >     }
>    > }
>    > ```
>    >
>    > ### 3. 混合分配策略
>    >
>    > #### 自适应分配（Adaptive Allocation）
>    > Streamflow结合小块内存和大块内存的分配策略，采用自适应分配策略，根据内存请求的大小和类型，选择最合适的分配路径。
>    >
>    > - **小块优先**：对于小块内存请求，优先使用线程局部缓存和固定大小分配策略，以确保低延迟和高并发性能。
>    > - **大块优化**：对于大块内存请求，使用分区分配和分级自由列表，以减少内存碎片并提高分配效率。
>    > - **动态调整**：系统根据运行时的内存使用情况，动态调整内存池的大小和分配策略，以优化性能。
>    >
>    > #### 示例
>    > ```c
>    > void* allocate_memory(size_t size) {
>    >     if (size <= SMALL_BLOCK_THRESHOLD) {
>    >         return allocate_small_block(size);
>    >     } else {
>    >         return allocate_large_block(size);
>    >     }
>    > }
>    > 
>    > void free_memory(void* block, size_t size) {
>    >     if (size <= SMALL_BLOCK_THRESHOLD) {
>    >         free_small_block(block);
>    >     } else {
>    >         free_large_block(block);
>    >     }
>    > }
>    > ```
>    >
>    > ### 总结
>    > Streamflow通过结合多种内存分配策略，优化了不同大小和类型的内存请求，从而提高了内存分配效率和并发性能。小块内存使用快速分配算法和线程局部缓存，大块内存采用分区分配和分级自由列表。这些策略的结合，使得Streamflow能够高效管理内存，同时减少内存碎片和分配延迟。
>
> 8. **SuperMalloc**
>
>    - **全称**：SuperMalloc
>    - **管理内存方式**：基于大页和快速分配策略优化性能。
>    - **针对问题**：提高分配性能和减少内存碎片。
>    - **考虑点**：大页支持和快速分配。
>
>    > ### 核心创新点
>    >
>    > 1. **分布式哈希表（Distributed Hash Table, DHT）**
>    >
>    >    - SuperMalloc使用分布式哈希表来管理内存块。每个线程都有自己的哈希表，用于存储和检索分配的内存块。这减少了全局锁的使用，提高了分配和释放操作的并发性能。
>    >
>    > 2. **大页支持（Huge Pages Support）**
>    >
>    >    - SuperMalloc利用操作系统的大页（Huge Pages）功能来减少内存管理开销。大页内存块比传统的小页内存块更大，减少了页表项的数量，从而提高了内存访问性能。
>    >
>    > 3. **缓存感知（Cache-Aware）**
>    >
>    >    - SuperMalloc的设计考虑了缓存感知，优化了内存访问模式以减少缓存失效。通过将频繁访问的内存块分配在同一缓存行或相邻的缓存行中，SuperMalloc提高了内存访问的局部性和性能。
>    >
>    >    >
>    >    > SuperMalloc通过多种技术手段实现缓存感知（Cache-Aware），以优化内存访问模式并减少缓存失效。以下是SuperMalloc在缓存感知方面的具体实现方法：
>    >    >
>    >    > ### 1. **内存对齐**
>    >    >
>    >    > SuperMalloc确保分配的内存块对齐到缓存行边界。这样可以减少缓存行之间的冲突，提高内存访问的效率。通常，缓存行大小为64字节，通过内存对齐可以确保数据结构在缓存中的局部性。
>    >    >
>    >    > ### 2. **分区分配**
>    >    >
>    >    > SuperMalloc将内存分配划分为多个分区，每个分区负责特定大小范围的内存块。通过这种方式，相关的数据结构和对象可以被分配到同一个分区，从而增加缓存命中率。
>    >    >
>    >    > ### 3. **对象池（Object Pool）**
>    >    >
>    >    > SuperMalloc使用对象池技术管理内存块。对象池将相同类型和大小的对象集中存储，以减少内存碎片和提高缓存局部性。
>    >    >
>    >    > ### 4. **数据预取（Data Prefetching）**
>    >    >
>    >    > SuperMalloc通过数据预取技术，在内存分配时预取未来可能访问的数据，以减少缓存未命中带来的延迟。这可以通过硬件预取指令或者软件预取实现。
>    >    >
>    >    > ### 5. **批量分配**
>    >    >
>    >    > SuperMalloc通过批量分配内存块来提高缓存局部性。批量分配可以将相关联的内存块一次性分配到相邻的缓存行中，提高缓存命中率。
>    >    >
>    >    > ### 6. **内存布局优化**
>    >    >
>    >    > SuperMalloc优化内存布局，使得相关数据结构和对象在内存中紧密排列，从而提高缓存局部性。例如，在分配对象时，确保对象的关键字段位于同一缓存行中，减少缓存行冲突。
>    >
>    > 4. **无锁自由列表（Lock-Free Free Lists）**
>    >
>    >    - 为了减少线程间的争用，SuperMalloc使用无锁自由列表管理空闲的内存块。这些无锁数据结构允许多个线程同时进行内存分配和释放操作，而不会产生锁争用和上下文切换开销。
>    >
>    > 5. **延迟内存回收（Deferred Memory Reclamation）**
>    >
>    >    - SuperMalloc采用延迟内存回收策略，避免了频繁的内存回收操作对性能的影响。内存块在释放后不会立即被回收，而是被标记为可回收状态，并在适当的时候统一回收。
>    >
>    > 6. **批量操作（Batching Operations）**
>    >
>    >    - SuperMalloc支持批量分配和释放内存块，通过将多个内存操作合并为一个批处理操作，减少了系统调用和内存管理的开销，提高了整体性能。
>    >
>    > 7. **自适应分配策略（Adaptive Allocation Strategy）**
>    >
>    >    - SuperMalloc根据运行时的内存使用情况和线程的访问模式，动态调整内存分配策略。这样可以在不同的工作负载下都能提供最佳性能。
>
> 9. **TBB (Threading Building Blocks malloc)**
>    - **全称**：Threading Building Blocks malloc
>    - **管理内存方式**：使用TBB库中的分配器，优化并发性能。
>    - **针对问题**：多线程环境中的内存分配。
>    - **考虑点**：并发性能和可扩展性。
>
> ### 为什么说Jemalloc采用固定大小的多级内存分配算法，很容易导致内存浪费，并且在内存分配速度上比TCMalloc稍慢？
>
> 1. **固定大小的多级内存分配算法**：
>    - Jemalloc使用多级分配器，每一级都有固定大小的内存块。这种策略虽然减少了内存碎片，但可能导致内存浪费，因为每个分配的内存块大小是固定的，不能灵活调整。
>    - 当需要分配的内存大小与预设的块大小不匹配时，会导致一些未使用的内存块无法有效利用，产生内存浪费。
>
> 2. **内存分配速度**：
>    - TCMalloc采用线程局部缓存策略，可以减少线程间的锁争用，从而提高分配速度。每个线程有自己的缓存，减少了全局锁的使用。
>    - Jemalloc虽然也有类似的优化，但其多级分配策略和更复杂的内存管理结构使其在某些情况下分配速度略慢于TCMalloc。
>
> 因此，Jemalloc在减少内存碎片方面表现出色，但在某些高并发场景下，其固定大小的分配块和多级结构可能会导致一些内存浪费，并且在分配速度上略逊于TCMalloc。



(3) mimalloc

Mimalloc是微软开发的一个轻量级内存分配器。它在性能和代码大小方面表现非常好。与tcmalloc、jemalloc相比，性能提升10%左右。

Mimalloc 不能与其他分配器共存，必须完全替代现有的内存分配器，因此在某些特殊场景下可能会存在一定的限制。

> **Mimalloc 的核心创新**
>
> 
>
> ​	1.	**分区分配（Segmented Allocation）**：
>
> ​	•	Mimalloc 将内存分配任务分散到多个独立的区域（segments）中，每个区域独立管理内存，从而减少锁争用。
>
> ​	2.	**延迟回收（Delayed Coalescing）**：
>
> ​	•	Mimalloc 在内存释放时不会立即合并相邻的空闲块，而是延迟这种操作，以减少不必要的合并和拆分操作。
>
> ​	3.	**线程本地缓存（Thread-local Caches）**：
>
> ​	•	Mimalloc 使用线程本地缓存，允许每个线程在本地缓存中进行小规模内存分配和释放操作，从而提高多线程程序的性能。
>
> ​	4.	**跨平台支持**：
>
> ​	•	Mimalloc 设计为跨平台内存分配器，可以在 Windows、Linux、macOS 等多个平台上运行。
>
> ​	5.	**轻量级设计**：
>
> ​	•	Mimalloc 的实现相对简洁，代码库较小，减少了内存管理的开销。
>
> 
>
> **Supermalloc 的核心创新**
>
> 
>
> ​	1.	**超大页支持（Superpage Support）**：
>
> ​	•	Supermalloc 使用超大页（superpages）来减少 TLB（翻译后备缓冲区）命中率，提高内存访问性能。
>
> ​	2.	**并发优化（Concurrency Optimization）**：
>
> ​	•	Supermalloc 采用细粒度锁和无锁数据结构，优化了多线程环境下的并发性能。
>
> ​	3.	**内存对象分类（Object Classification）**：
>
> ​	•	Supermalloc 通过对不同大小的内存对象进行分类，并分别管理它们，以减少内存碎片并提高分配效率。
>
> ​	4.	**按需分配（On-demand Allocation）**：
>
> ​	•	Supermalloc 仅在需要时分配内存，避免了预先分配大量内存的开销。
>
> ​	5.	**延迟回收和合并（Lazy Coalescing and Merging）**：
>
> ​	•	Supermalloc 在内存回收时采用延迟策略，并在适当时机进行内存块的合并操作。

(4) dlmalloc

Dlmalloc 是 glibc 中使用的内存分配器。由于采用了阻塞技术，减少了内存分配过程中的内存碎片，从而提高了内存利用率。它还支持多线程并发操作，可以满足高并发、高负载的应用场景的需求。在大规模内存分配场景下，dlmalloc的内存分配速度比较快，适合高并发、高吞吐量的应用场景。

dlmalloc阻塞过程可能会造成内存浪费，因此不适合一些内存使用率较低的应用场景。

## 2 BFC GPU 内存池

与内存池类似，GPU内存池主要解决两类问题。一是提高gpu内存频繁申请和释放的效率，二是减少gpu内存碎片的产生。另一方面，GPU在处理GPU内存事务时可能会包含隐式同步操作，从而影响程序性能。

> **GPU 内存事务中的隐式同步操作**
>
> 
>
> ​	1.	**内存事务**：指的是 GPU 在执行内存操作时，包括内存的读、写、复制等。常见的内存事务包括从主机（CPU）到设备（GPU）的内存复制（Host-to-Device）、从设备到主机的内存复制（Device-to-Host）、设备内部的内存复制（Device-to-Device）等。
>
> ​	2.	**隐式同步操作**：在某些内存事务中，GPU 会自动插入同步操作，以确保数据的一致性和正确性。这些同步操作通常是不显式暴露给开发者的，因此称为隐式同步操作。
>
> 
>
> **隐式同步操作的原因**
>
> 
>
> 隐式同步操作的主要原因包括以下几方面：
>
> 
>
> ​	1.	**数据一致性**：确保在内存复制操作前后，数据的一致性。例如，在将数据从主机复制到设备前，可能需要确保主机内存的写操作已经完成。
>
> ​	2.	**内存访问顺序**：确保内存访问的顺序是正确的，避免数据竞争。例如，在一个内存操作还未完成时，防止其他内存操作对同一地址的访问。
>
> ​	3.	**内核执行依赖**：确保在某些内存操作完成后，GPU 内核的执行才开始。例如，在数据复制完成后，才启动依赖于该数据的 GPU 计算内核。
>
> 
>
> **隐式同步操作对性能的影响**
>
> 
>
> 隐式同步操作可能会影响 GPU 程序的性能，具体体现在以下几个方面：
>
> 
>
> ​	1.	**延迟增加**：隐式同步操作会导致额外的等待时间，增加内存事务的延迟。例如，在数据从主机复制到设备时，需要等待主机的写操作完成。
>
> ​	2.	**并行性降低**：隐式同步操作会阻碍 GPU 的并行执行能力。GPU 的设计初衷是大规模并行计算，如果存在隐式同步操作，会导致部分计算单元处于等待状态，从而降低整体的并行度。
>
> ​	3.	**资源利用率降低**：隐式同步操作会导致计算资源和内存带宽的利用率降低。例如，在等待内存事务完成的过程中，计算资源可能处于闲置状态。

Tensorflow提出的BFC（Best-Fit with Coalescing）GPU内存管理算法是dlmalloc算法的简单版本，支持多线程场景，可以非常高效地分配和回收GPU内存块，并尽可能减少GPU内存碎片。