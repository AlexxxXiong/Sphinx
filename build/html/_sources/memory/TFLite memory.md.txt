# **优化 TensorFlow Lite 运行时内存**

> **它的优化目标是得到中间张量最小的空间，然后开辟给神经网络。**

由于资源紧张，在移动和嵌入式设备上运行推理具有挑战性；人们必须在严格的功率要求下使用有限的硬件工作。在本文中，我们希望展示 TensorFlow Lite (TFLite) 内存使用方面的改进，使其能够更好地在边缘运行推理。

## 中间张量

中间张量不必在内存中共存。这使我们能够重用中间张量的内存缓冲区并减少推理引擎的总内存占用。如果网络具有简单链的形状，则两个大内存缓冲区就足够了，因为它们可以在整个网络中来回交换。**然而，对于形成复杂图的任意网络，这种NP完全 资源分配问题需要良好的近似算法。**

我们针对这个问题设计了许多不同的近似算法，它们的表现都不同，具体取决于神经网络和内存缓冲区的属性，但它们都使用一个共同点：**张量使用记录。**中间张量的张量使用记录是一种辅助数据结构，包含有关张量有多大以及在网络给定执行计划中第一次和最后一次使用的信息。借助这些记录，内存管理器能够计算网络执行过程中任何时刻的中间张量使用情况，并优化其运行时内存以尽可能减少占用空间。

## 共享内存缓冲区对象

在TFLite GPU OpenGL 后端中，我们对这些中间张量使用 GL 纹理。它们有一些有趣的限制：(a) 纹理的大小在创建后无法修改，(b) 在给定时间只有一个着色器程序能够独占访问纹理对象。在这种共享内存缓冲区对象模式下，目标是最小化对象池中所有创建的共享内存缓冲区对象的大小总和。这种优化类似于众所周知的[寄存器分配问题](https://en.wikipedia.org/wiki/Register_allocation)，只不过由于每个对象的大小可变，它要复杂得多。

根据前面提到的张量使用记录，我们设计了 5 种不同的算法，如表 1 所示。除了 Min-Cost Flow 之外，它们都是贪心算法，每种算法都使用不同的启发式，但仍然达到或非常接近理论下界。根据网络拓扑，某些算法的性能优于其他算法，但一般来说，GREEDY_BY_SIZE_IMPROVED它们GREEDY_BY_BREADTH会生成具有最小内存占用的对象分配。

回到我们开头的示例，`GREEDY_BY_BREADTH`MobileNet v2 的性能最佳，它利用了每个算子的广度，即算子配置文件中所有张量的总和。

## 内存偏移计算

https://arxiv.org/abs/1804.10001

对于在 CPU 上运行的 TFLite，适用于 GL 纹理的内存缓冲区属性不适用。因此，更常见的是预先分配一个巨大的内存区域，并在所有读取器和写入器之间共享它，这些读取器和写入器通过不干扰其他读取和写入的给定偏移量访问它。这种**内存偏移计算**方法的目标是**最小化内存区域的大小。**

与共享对象方法类似，一些算法的性能优于其他算法，具体取决于网络，如表 2 所示。这项研究的一个要点是，**偏移计算方法的占用空间通常比共享对象方法小，**因此，如果适用的话，应该优先选择前者而不是后者。