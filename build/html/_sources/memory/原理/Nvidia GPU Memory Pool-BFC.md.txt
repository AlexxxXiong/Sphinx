# Nvidia GPU Memory Pool-BFC

----

内存池是linux系统中一种高效的内存管理机制。它预先分配一定数量的内存块并形成一个池，以便在需要内存时可以快速分配内存。与传统的内存分配方式相比，内存池管理可以大大提高内存分配和释放的效率，减少内存碎片的产生。



在计算机内存管理中，伙伴系统和页表有不同的角色，但它们之间仍然存在联系。让我们分别定义这两个概念，并了解它们之间的联系。

### 1. 页表（Page Table）
- **功能：** 将虚拟地址映射到物理地址，实现虚拟内存管理。
- **结构：**
  - 由页目录（Page Directory）和页表（Page Table）构成。
  - 虚拟地址通过多级页表转换成物理地址。
  - 虚拟地址通常分成页目录、页表和页偏移三个部分。
  
### 2. 伙伴系统（Buddy System）
- **功能：** 管理物理内存的分配与释放。
- **结构：**
  - 将物理内存按2的幂次划分成多个块（block），每个大小称为一个order。
  - 每个order的块按大小分类成不同的`bin`，在每个`bin`中包含多个块，称为`chunk`或`block`。

### 页表和伙伴系统之间的联系
1. **物理内存的管理：**
   - 页表管理虚拟地址空间的映射。
   - 页表中的物理页框号指向实际的物理内存地址。
   - 伙伴系统在物理内存中维护这些物理页框。
   - 因此，伙伴系统通过页表提供的虚拟地址映射，管理实际的物理内存。

2. **物理页框的分配：**
   - 页表中的每个页框指向一个实际的物理页。
   - 当需要分配新的页框时，伙伴系统负责分配实际的物理内存。
   - 伙伴系统根据页表的映射关系，将物理内存分配给特定的虚拟地址空间。

3. **内存回收：**
   - 当释放内存时，页表会更新映射关系，标记相应的页框为可用状态。
   - 伙伴系统接管已释放的物理页框，并将其重新加入适当的`bin`。

### 简化的关系示意图
```
虚拟内存 -> 页表 -> 物理页框号 -> 伙伴系统的`bin`（物理内存块）
```

### 流程举例
1. **分配内存：**
   1. 请求从虚拟内存分配一个页面。
   2. 查找页表，将虚拟页映射到一个空闲的物理页框。
   3. 伙伴系统为物理页框分配实际的内存块。

2. **释放内存：**
   1. 请求释放某个虚拟内存页面。
   2. 更新页表映射，标记对应的物理页框为可用。
   3. 伙伴系统将该物理内存块返回到合适的`bin`中。

### 结论
- 页表和伙伴系统通过虚拟地址到物理地址的映射关系建立联系。
- 页表负责管理虚拟地址空间，伙伴系统负责实际的物理内存管理。
- 伙伴系统与页表的结合提供了高效的虚拟内存管理与物理内存分配。







## 1.1 Linux内核内存池

- **Buddy 系统**：操作系统通常使用 `Buddy` 系统来分配和管理内存块。然而，`Buddy` 系统更适合管理大块内存，对于小对象的频繁分配与释放效率较低。
- **内存碎片**：频繁的小对象分配和释放容易导致大量内存碎片，降低内存利用效率。

在linux内核中，内存池管理主要采用以下两种方法：

### (1) Buddy System

伙伴系统以页为单位管理和分配内存。内存池中所有内存块的大小为2^n。

它将所有空闲页框分组到11个块链表中。

每个块链表包含大小为1、2、4、8、16、32、64、128、256、512和1024个连续页框的页框块。

当需要分配一块内存时，分配器会在内存池中找到最小的可用块，并将其分配给用户。

当不再使用某个内存块时，分配器将释放它并检查其“兄弟块”。

如果兄弟块也空闲，则将它们合并成一个大块，并继续向上检查，直到无法再合并为止。 



buddy系统的优点是可以减少内存碎片的产生，同时也提高了内存分配的效率。

然而，这种方法也有一些缺点。例如，大小不规则的内存块的分配和释放不方便，还可能存在内存的浪费。





### (2) Slab Allocator

slab分配器是在buddy系统分配的大内存的基础上进一步细化的小内存分配方法。

主要针对一些经常分配和释放的小对象，通常是内核数据结构。

**每当申请这样的对象时，slab分配器就会从slab列表中分配一个这个大小的单元，**

**当它被释放时，再次将其保存在列表中，而不是直接返回给伙伴系统，从而避免内部碎片。**



lab分配器可以高效地处理频繁申请和释放小对象（例如内核数据结构）的内存事务。

同时，可以显着节省内存空间，避免过多的内存碎片。



#### Slab 分配器的结构与工作机制

1. **Slab、Cache 和 Object**
   - **Slab**：由一块连续的物理内存区域组成，包含若干固定大小的对象。
   - **Cache**：由多个 Slab 组成，针对特定类型的小对象（如内核数据结构）进行优化管理。
   - **Object**：实际的小对象，保存在 Slab 内。
2. **分配与释放流程**
   - **分配对象**：
     - 当请求一个小对象时，Slab 分配器会从目标 Cache 中的 Slab 列表中分配一个空闲对象。
     - 如果当前 Cache 中没有空闲的 Slab，可以从 `Buddy` 系统申请一个新的 Slab，并将其添加到 Cache 中。
     - 分配成功的对象会标记为已使用状态。
   - **释放对象**：
     - 当对象被释放时，Slab 分配器将其标记为可用，并返回到相应的 Slab。
     - **该对象不会立即归还给 `Buddy` 系统，而是保持在 Cache 中以供后续分配使用。**
     - **如果一个 Slab 中的所有对象都空闲，则该 Slab 可以被归还给 `Buddy` 系统。**
3. **避免内部碎片**
   - **保持对象池**：对象释放后保持在 Cache 中而不是直接归还给 `Buddy` 系统，从而避免内部碎片。
   - **预分配对象池**：每个 Cache 都有一个预分配对象池（即空闲对象列表），减少频繁的分配与释放操作。

```c
struct kmem_cache {
    ...
    struct list_head slabs_full;    // 满载的 Slab 链表
    struct list_head slabs_partial; // 部分使用的 Slab 链表
    struct list_head slabs_free;    // 空闲的 Slab 链表
    ...
};

void *kmem_cache_alloc(struct kmem_cache *cache, gfp_t flags) {
    struct slab *slab;
    void *obj;

    // 从部分使用的 Slab 链表中分配对象
    slab = list_first_entry_or_null(&cache->slabs_partial, struct slab, list);
    if (slab) {
        obj = slab_alloc(slab, cache, flags);
        if (obj) {
            return obj;
        }
    }

    // 如果没有可用的对象，分配新的 Slab
    slab = kmem_cache_grow(cache, flags);
    if (!slab) {
        return NULL;
    }

    // 从新分配的 Slab 中分配对象
    return slab_alloc(slab, cache, flags);
}

```



### 主要优点

1. **效率高**：
   - **频繁分配和释放**：针对内核数据结构等频繁分配和释放的小对象操作提供优化。
   - **预分配对象池**：对象池中的对象可以快速重复使用。
2. **内存节省**：
   - **减少内存碎片**：通过保持对象池避免了直接归还给 `Buddy` 系统而产生的内部碎片。
   - **对象重用**：保持对象池中的对象以供快速分配和重用。

### 总结

这段话主要强调了以下内容：

1. **Slab 分配器的作用**：针对频繁分配和释放的小对象提供更高效的内存管理。

2. **工作机制**：保持对象池避免内部碎片，快速分配与释放对象。

3. 优势

   ：

   - 避免直接归还给 `Buddy` 系统导致的内部碎片。
   - 高效处理频繁的小对象内存事务。













对于TensorFlow和PyTorch的内存分配机制及其初始分配规则，可以通过查看它们的源代码来获取更详细的信息。下面是一些指导，帮助你了解这些规则在源代码中是如何实现的：

### TensorFlow

在TensorFlow中，内存管理主要由BFC（Best-Fit with Coalescing）分配器处理，它负责GPU内存的分配。要找到与内存分配相关的代码和初始分配规则：

- **源码位置**：TensorFlow的内存分配器实现位于`tensorflow/core/common_runtime/bfc_allocator.cc`。这里包含了BFC分配器的逻辑，包括它是如何初始化内存池的。
- **初始化规则**：在BFC分配器的初始化过程中，会基于用户的配置或默认设置来决定初始的内存大小。如果启用了内存增长，初始分配通常较小，并根据需要进行调整。

### PyTorch

PyTorch使用缓存分配器来管理CUDA内存，这种策略的实现有助于动态地回收和重新分配内存，从而优化内存使用：

- **源码位置**：PyTorch的CUDA内存分配器代码主要在`c10/cuda/CUDACachingAllocator.cpp`中。这个文件包含了缓存分配器的核心实现。
- **初始化规则**：PyTorch的内存分配器在模型开始运行时不会立即申请大量内存。它根据模型运行时的需求动态地分配和释放内存，初始分配通常是按需进行的。

这些文件包含了内存分配的具体实现逻辑，你可以通过查看这些源文件来获取关于内存分配策略和初始化规则的详细信息。如果你对源代码有进一步的问题或需要帮助理解特定部分，随时可以询问！





## 1.2 其他内存池

(1) tcmalloc

Tcmalloc是Google开发的高效稳定的内存分配器。它采用slab技术，可以有效避免内存碎片。在多线程环境下的性能非常好，速度也比较快，适合在大规模、高并发的分布式集群系统中使用。同时支持调整参数，可以根据不同的应用场景和硬件配置进行适当调整，使内存分配更加高效。

tcmalloc不支持动态内存分配，因此不能与系统内置的内存分配器交互使用。并且由于tcmalloc需要优化，需要增大二进制文件的大小，影响加载速度。

(2) jemalloc

Jemalloc 是 FreeBSD 开发的通用内存分配器。它主要使用分层分配来管理内存。在多线程环境下，尤其是在虚拟机中，具有出色的分配和释放性能。并取得了良好的业绩。

Jemalloc采用固定大小的多级内存分配算法，很容易导致内存浪费，并且在内存分配速度上比tcmalloc稍慢。

> 这些都是知名的内存分配器。以下是它们的全称及简要介绍：
>
> 1. **jemalloc (Jason Evans malloc)**
>    - **全称**：Jason Evans Memory Allocator
>    - **管理内存方式**：使用分层结构和多级内存池来管理内存。通过合并空闲块来减少内存碎片。
>    - **针对问题**：优化内存分配性能和减少内存碎片。
>    - **考虑点**：平衡内存使用效率和分配速度。
>
> 2. **llalloc (Low Latency Alloc)**
>    - **全称**：Low Latency Allocator
>    - **管理内存方式**：旨在提供低延迟内存分配，特别适用于实时系统。
>    - **针对问题**：降低内存分配和释放的延迟。
>    - **考虑点**：极低的分配延迟。
>
> 3. **ptmalloc2 (Pthreads malloc 2)**
>    - **全称**：Pthreads Memory Allocator 2
>    - **管理内存方式**：基于Doug Lea的dlmalloc改进，支持多线程环境。
>    - **针对问题**：多线程环境中的内存分配。
>    - **考虑点**：线程安全和性能。
>
> 4. **TCMalloc (Thread-Caching Malloc)**
>    - **全称**：Thread-Caching Malloc
>    - **管理内存方式**：使用线程局部缓存减少锁争用，提高多线程环境中的分配速度。
>    - **针对问题**：高并发环境下的内存分配效率。
>    - **考虑点**：减少锁争用，提高分配速度。
>
> 5. **Hoard**
>    - **全称**：Hoard Memory Allocator
>    - **管理内存方式**：使用分级分配器和局部缓存来减少内存碎片和提高多线程性能。
>    - **针对问题**：减少内存碎片和提高多线程环境的性能。
>    - **考虑点**：线程局部缓存和全局缓存的平衡。
>
> 6. **scalloc (Scalable Malloc)**
>    - **全称**：Scalable Malloc
>    - **管理内存方式**：设计用于多核处理器的分配器，减少同步开销。
>    - **针对问题**：多核处理器环境下的内存分配效率。
>    - **考虑点**：减少同步开销，提高并发性。
>
> 7. **Streamflow**
>    - **全称**：Streamflow Memory Allocator
>    - **管理内存方式**：通过分配器池和流式分配策略来减少内存碎片。
>    - **针对问题**：减少内存碎片和提高分配性能。
>    - **考虑点**：流式分配策略。
>
> 8. **SuperMalloc**
>    - **全称**：SuperMalloc
>    - **管理内存方式**：基于大页和快速分配策略优化性能。
>    - **针对问题**：提高分配性能和减少内存碎片。
>    - **考虑点**：大页支持和快速分配。
>
> 9. **TBB (Threading Building Blocks malloc)**
>    - **全称**：Threading Building Blocks malloc
>    - **管理内存方式**：使用TBB库中的分配器，优化并发性能。
>    - **针对问题**：多线程环境中的内存分配。
>    - **考虑点**：并发性能和可扩展性。
>
> ### 为什么说Jemalloc采用固定大小的多级内存分配算法，很容易导致内存浪费，并且在内存分配速度上比TCMalloc稍慢？
>
> 1. **固定大小的多级内存分配算法**：
>    - Jemalloc使用多级分配器，每一级都有固定大小的内存块。这种策略虽然减少了内存碎片，但可能导致内存浪费，因为每个分配的内存块大小是固定的，不能灵活调整。
>    - 当需要分配的内存大小与预设的块大小不匹配时，会导致一些未使用的内存块无法有效利用，产生内存浪费。
>
> 2. **内存分配速度**：
>    - TCMalloc采用线程局部缓存策略，可以减少线程间的锁争用，从而提高分配速度。每个线程有自己的缓存，减少了全局锁的使用。
>    - Jemalloc虽然也有类似的优化，但其多级分配策略和更复杂的内存管理结构使其在某些情况下分配速度略慢于TCMalloc。
>
> 因此，Jemalloc在减少内存碎片方面表现出色，但在某些高并发场景下，其固定大小的分配块和多级结构可能会导致一些内存浪费，并且在分配速度上略逊于TCMalloc。



