# hot-n-cold page

----------

Linux 内核 2.5.45 中引入的 “hot-n-cold page” 补丁，旨在优化内核的内存页分配，特别是与 CPU 缓存相关的性能改进。这个补丁通过将物理页面按“热”和“冷”两类进行区分，最大化利用 CPU 缓存，提高系统整体性能。



2.5.45 内核中的众多更改之一是 Martin Bligh、Andrew Morton 等人提供的“hot-n-cold page”补丁。这是一个概念上简单的改变，显示了要处理现代系统架构的现实需要走多远。

人们通常认为系统 RAM 是保存数据最快的地方。但记忆力很慢；真正*的*速度来自处理器本身的板载缓存。多年来，**人们付出了很多努力来尝试优化内核的缓存行为并避免访问主内存。新的页面分配系统只是朝这个方向迈出的又一步。**

**处理器高速缓存包含最近访问过的内存。**内核通常很清楚哪些页面最近被访问过，因此可能存在于缓存中。**热-冷补丁尝试通过添加两个每 CPU 空闲页面列表（针对每个内存区域）来利用该信息**。当处理器释放被怀疑为“热”的页面（即在该处理器的缓存中表示）时，它将被推入热列表；其他人则进入冷名单。该列表有上限和下限；毕竟，如果热列表变得大于处理器的缓存，那么这些页面实际上开始热的可能性就会变得非常小。

当内核需要内存页面时，新的分配器通常会尝试从处理器的热列表中获取该页面。即使页面只是被覆盖，最好还是使用缓存热页面。但有趣的是，有时使用冷页面是有意义的。如果该页用于 DMA 读取操作，则该页将由执行该操作的设备填充，并且无论如何缓存都会失效。因此，2.5.45 包含一个新的 `GPF_COLD`页面分配标志，适用于使用冷页面更有意义的情况。

**使用每 CPU 页面列表还可以减少锁争用，这也有助于提高性能。当页面必须在热/冷列表和主内存分配器之间移动时，它们会以多页面块的形式传输，这也减少了锁争用并使事情进展得更快。**

Andrew Morton 对这个补丁进行了基准测试，并包含了其中一个补丁集 的许多结果。性能优势各不相同，从最重要的内核编译时间的 1-2% 到 SDET 测试的 12%。显然，这足以说服莱纳斯。



ChangeSet 1.907, 2002/10/30 15:35:32-08:00, akpm@digeo.com

【补丁】热冷页：批量页分配器

这是热冷页系列的一部分。它在页分配器前引入了一个每CPU无锁后进先出（LIFO）池，这主要基于三个原因：

1：减少对伙伴锁的竞争：我们通常以16页的块进行页面的分配和释放。

2：将缓存热页返回给页面分配请求。

3：作为一个页面预留API的基础设施，该API用于确保GFP_ATOMIC基数树节点和pte_chain分配不会失败。该代码尚未完成，且并非绝对需要热冷页。不过，它运行还算可以。

我们为每个CPU添加了两个队列。"热"队列包含了释放代码认为可能是缓存热的页面。默认情况下，新的分配将从此队列满足。

**"冷"队列包含了释放代码预期为缓存冷的页面。冷队列主要用于锁的摊销，尽管可以显式地分配冷页。预读代码就是这么做的。**

我对这些补丁已经犹豫了相当长时间 - 因为收益并不大。

- Randy Hron的autoconf回归测试在四路系统上的基准测试速度提升了4%。其中大部分来自于pte_alloc和pmd_alloc的节省：页面表清除代码喜欢更温暖的页面（一些架构仍然有pgt_cache，或许可以摆脱它们）。

- 在我的四路和Martin的三十二路系统上，内核编译速度提升了1%到2%。

- 在一个小测试程序中，速度提升了60%，该程序将80千字节写入一个文件，然后再将其截断为零。在四路系统上运行了四个实例，它们喜欢缓存的温度。

- 在八路系统上进行Specweb测试的速度提升了2.5%。

- 最终打动我的是，SDET基准测试在八路PIII系统上的吞吐量提高了11%：

  使用热与冷：

  8用户的结果是17971    +12.1%
  16用户的结果是17026   +12.0%
  32用户的结果是17009   +10.4%
  64用户的结果是16911   +10.3%

  不使用：

  8用户的结果是16038
  16用户的结果是15200
  32用户的结果是15406
  64用户的结果是15331

  SDET是一个非常老的SPEC测试，它模拟了一个有大量用户的开发环境。基本上是许多用户运行一系列的shell命令。

这些补丁由Martin Bligh和我编写。

这个补丁实现了rmqueue_bulk() - 一个从伙伴列表中移除给定顺序的多个页面的函数。

这是为了锁摊销：减少高度竞争的zone->lock的频繁获取，一旦获得则做更多的工作。





在Linux内核的内存管理中，伙伴系统（Buddy System）是一种用于管理物理内存的算法，旨在有效地分配和释放内存块，减少碎片。在这个系统中，“伙伴锁”是指用来同步对伙伴系统数据结构访问的锁机制。

### 伙伴系统简介
伙伴系统通过将内存分为一系列的大小为2的幂的块来工作。每次内存分配或释放请求都涉及到对这些块的操作。当一个内存块被释放时，伙伴系统会检查其“伙伴”（即大小相同且地址连续的块）是否也是空闲的。如果是，两个伙伴块就会合并成一个更大的块。这有助于保持内存的整合，减少碎片。

### 伙伴锁的作用
由于多个CPU可能同时尝试分配或释放内存块，因此需要一种同步机制来保护伙伴系统的数据结构不被并发访问所破坏。伙伴锁就是这种机制。它是一个互斥锁，用于同步对伙伴系统中的自由列表的访问。每次当内核代码需要修改这些列表（例如，添加或移除内存块）时，它必须首先获取伙伴锁。

### 伙伴锁的影响
虽然伙伴锁提供了必要的数据保护，使得内存管理在多处理器环境中保持一致和安全，但它也可能成为性能瓶颈。特别是在高负载时，多个处理器核心可能会竞争同一把锁，导致延迟和性能下降。

因此，如提到的“热冷页”补丁中所做的那样，寻找减少对伙伴锁依赖的方法（例如通过引入本地CPU缓存队列）可以显著提升性能，因为它减少了对全局锁的竞争，使得内存分配更加高效。这种改进特别在多核处理器系统中显得非常重要，可以显著提升多任务处理和高并发场景下的系统表现。



在谈论“缓存结构”时，我们通常是指构成缓存硬件或软件实现的多个关键组成部分，这些组件的设计和配置直接影响缓存的性能和效率。下面是一些构成缓存结构的基本要素：

### 1. 缓存大小
- **缓存大小**是指缓存可以存储数据的总量，通常以字节为单位。缓存大小直接影响到可以被快速访问的数据量，较大的缓存可能提高命中率，但也可能增加缓存的访问时间和成本。

### 2. 关联度
- **关联度**描述了一组缓存中可以存放多少行数据。它决定了在缓存中查找数据时的灵活性。
  - **直接映射缓存**：每个缓存块只有一个可能的位置（关联度为1）。
  - **全相联缓存**：任何缓存块都可以放在缓存中的任何位置（关联度等于缓存块的总数）。
  - **组相联缓存**：是直接映射和全相联的折中方案，缓存被分为若干组，每组有多个缓存块。

### 3. 行大小
- **行大小**（或块大小）是指单个缓存行能够存储的数据量。行大小影响了数据的加载效率，较大的行可以减少I/O操作的次数，但如果程序的空间局部性不好，可能会导致更多的无用数据被加载到缓存中。

### 4. 替换策略
- **替换策略**决定了当缓存满时哪些数据应该被替换或移除，以为新数据腾出空间。常见的替换策略包括：
  - 最近最少使用（LRU）：淘汰最长时间未被访问的数据。
  - 先入先出（FIFO）：按照数据进入缓存的顺序进行淘汰。
  - 随机替换：随机选择一个缓存块来替换。

### 5. 写策略
- **写策略**涉及到当数据被写入缓存时如何同步更新主存中的相应数据。
  - 写回（Write-back）：数据只在缓存中修改，只有在数据被替换出缓存时才回写到主存。
  - 写通（Write-through）：数据同时写入缓存和主存。

缓存结构的设计和选择取决于特定应用的需求，比如应用程序的访问模式、预期的工作负载特性以及性能和资源成本的考虑。调整缓存配置，如改变缓存大小、关联度或替换策略，可以帮助匹配具体应用的需求，从而优化性能和资源使用效率。





循环变换和阻塞技术（block tiling）是两种常用的编程优化技术，主要用于提高程序在内存和缓存系统中的性能。通过这些技术，程序员可以改善数据的局部性，从而提高缓存命中率并减少执行时间。下面分别解释这两种技术：

### 循环变换（Loop Transformation）

循环变换是对程序中循环结构进行修改的一种技术，目的是为了优化数据访问的模式和提高程序的性能。循环变换包括很多种具体技术，如循环展开（loop unrolling）、循环交换（loop interchange）、循环分割（loop fission）和循环合并（loop fusion）等。

- **循环展开**：通过减少循环迭代次数来减少循环开销，同时增加单次迭代中的操作数量。
- **循环交换**：在多重循环中交换内外循环的顺序，通常用来改善数组或矩阵数据的访问顺序，以匹配数据在内存中的布局。
- **循环分割和循环合并**：根据需要将一个大循环分割成多个小循环，或将多个小循环合并为一个大循环，以改善缓存利用率或减少循环中的依赖。

### 阻塞技术（Block Tiling）

阻塞技术，也称为块划分或瓷砖化（tiling），是一种处理多重循环（尤其是对数组和矩阵操作）时的优化技术。其核心思想是将大的数据集分割成小的块（blocks或tiles），使得每个数据块可以完全装入缓存中进行处理。

- **数据局部性优化**：通过处理小块数据，程序可以更频繁地访问缓存中的数据，从而减少访问主内存的需要。
- **例子**：在处理矩阵乘法时，可以将矩阵划分成较小的子矩阵块，然后分别计算这些块。这样，每个子矩阵块在计算过程中可以保持在CPU缓存中，直到计算完成。





**Hot-n-Cold Page Allocation**（热冷页面分配）是一种内存管理技术，旨在优化多核处理器环境中的内存性能。这种技术主要在操作系统的内核级别实现，尤其是在处理虚拟内存系统时。其核心思想是区分“热”页面和“冷”页面，从而更有效地管理内存，提高缓存的利用率，降低内存访问延迟。

### 热页和冷页的概念

1. **热页（Hot Pages）**：
   - 这些是频繁访问的内存页。因为它们被频繁使用，所以它们很可能已经在CPU的缓存中。操作系统试图保持这些页面在物理内存中的位置靠近处理器，以减少访问时间。

2. **冷页（Cold Pages）**：
   - 相对不常访问的内存页。这些页面可能不在缓存中，也不太可能很快再次被需要。操作系统可能会选择将这些页面移动到物理内存的较远位置，或者在需要为热页腾出空间时，将其交换出内存。

### 实现机制

在多核系统中，热冷页分配通常与NUMA（非一致性内存访问）架构结合使用。在NUMA架构中，不同的处理器或核心访问不同内存区域的成本可能不同。通过将热页放置在靠近当前访问它们的CPU的内存区域中，可以显著减少内存访问延迟。冷页由于访问频率低，可以放置在较远的内存节点上，从而为热页释放更宝贵的、接近CPU的内存空间。

### **优化和挑战**

- **优化：热冷页技术可以显著提高缓存的有效性和内存访问速度，特别是在高负载和高并发的环境中。**
- **挑战：正确地实施热冷页分配需要精确地监控和预测内存访问模式，这可能会增加操作系统的复杂性。此外，过度的页面迁移和错误的预测可能会导致性能下降。**

### 应用

这种技术被应用在需要高效内存管理的系统中，如数据库服务器、大规模并行处理系统和需要高响应速度的实时系统。Linux 内核等现代操作系统也实现了类似的内存管理技术，以提升在多核和多处理器环境下的性能。

总的来说，hot-n-cold page allocation 是一种高级的内存管理技术，通过智能地处理内存页面的位置和访问模式，可以显著提高系统性能。这要求操作系统能够智能地识别和适应不同的工作负载模式。